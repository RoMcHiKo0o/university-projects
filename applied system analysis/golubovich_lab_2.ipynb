{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "**Дата выдачи**: 16.09.2022/19.09.2022\n",
    "\n",
    "**Срок сдачи**: 30.09.2022/03.10.2022 *(Но требуется обязательная демонстрация текущего прогресса преподавателю во время лабораторного занятия 23.09.2022/26.09.2022)*\n",
    "\n",
    "### О задании\n",
    "Целью данного задания является ознакомление с основными методами первичного анализа данных, обучение моделей машинного обучения, снятие метрик качества работы этих моделей. Ознакомление с платформой *kaggle.com*\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдача заданий после указанного срока сдачи ведёт к снижению оценки.\n",
    "\n",
    "Задание выполняется САМОСТОЯТЕЛЬНО. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник). \n",
    "\n",
    "### Формат сдачи\n",
    "** Устная защита выполненной лабораторной работы ОБЯЗАТЕЛЬНА! **\n",
    "\n",
    "После успешной устной защиты переименуйте получившийся файл `*.ipynb` в соответствии со следующим форматом: *Username_lab_2.ipynb*, где Username — ваша фамилия на латинице (например, `lehusheu_lab_2.ipynb`) и отправьте этот файл электронной почтой по адресу `dmitri.legushev.bsu@gmail.com` c темой письма *Фамилия преподавателя - Лабораторная работа 2 - Фамилия Имя Отчество* (для обоих подгрупп). Подгруппа Атрохова Кирилла Георгиевича также ставит в копию адрес `?`. Это будет являться письменным отчетом о выполнении лабораторной работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача:** Используя алгоритмы машинного обучения, создать модели, которые предсказывают какой пассажир \n",
    "    выжил после крушения на Титанике. \n",
    "\n",
    "**Данные:** \n",
    "Обучающая выборка должна быть использована для построения ваших моделей машинного обучения. Для обучающей выборки есть таргет *survived*. \n",
    "\n",
    "Тестовая выборка таргета не имеет. Она должна использоваться для оценки качества работы ваших моделей на платформе *kaggle.com*\n",
    "\n",
    "**Подробнее о данных:** https://www.kaggle.com/competitions/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix,f1_score,accuracy_score,recall_score,precision_score, auc, roc_curve, RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Загрузить данные для обучения и теста, найти признаки с пропущенными значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Проанализировать все признаки. Для каждого признака определить:\n",
    "* Получить основные статистики (`describe`)\n",
    "* Количество пропусков\n",
    "* Тип признака (категориальные, текстовые, числовые)\n",
    "* Для категориальных данных определить уникальные значения\n",
    "* Для категориальных данных построить bar plot (`plt.bar()`), определить признаковое распредение значений\n",
    "* Для числовых признаков построить гистограмму (`plt.hist()`), попробовать разное количество бинов (*bins*) в разбиении. Определить тип распределения(равномерный, нормальный ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD1CAYAAACrz7WZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMoUlEQVR4nO3cf6jd9X3H8eerRl03h/HHXZAk9goNlMBWdXfO0jE6Qzd/lMU/WrGMGSRw/3HM4WDL9k8ZbKD/zFUYsjDdYtlmxa0kWFkXojLG0PVanda64q3okqDm1vpj4tqS9r0/7ifsmN7ruT/Ovcd88nzA5Xy/n+/33PO+nOSZwzfn3FQVkqS+fGjcA0iSRs+4S1KHjLskdci4S1KHjLskdci4S1KHNox7AIALL7ywJicnxz2GJJ1Snnzyye9W1cRCxz4QcZ+cnGRmZmbcY0jSKSXJy4sd87KMJHVoSXFP8lKSZ5M8nWSmrZ2f5GCSF9rteW09Se5KMpvkmSSXr+UPIEn6Sct55f5rVXVpVU21/T3AoaraBhxq+wDXANva1zRw96iGlSQtzWouy+wE9rXtfcD1A+v31bzHgY1JLlrF40iSlmmpcS/gX5I8mWS6rW2qqlfa9qvApra9GTg8cN8jbU2StE6W+m6ZX6mqo0l+DjiY5L8GD1ZVJVnWr5ds/0hMA1x88cXLuaskaYglvXKvqqPt9hjwFeAK4LUTl1va7bF2+lFg68Ddt7S1k7/n3qqaqqqpiYkF36YpSVqhoXFP8jNJfvbENvDrwDeBA8CudtouYH/bPgDc1N41cyXw1sDlG0nSOljKZZlNwFeSnDj/76vqn5N8HXggyW7gZeCGdv7DwLXALPAucPPIp16lyT1fHfcIa+ql268b9wiSxmxo3KvqReDjC6y/DuxYYL2AW0YynSRpRfyEqiR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1aMlxT3JGkqeSPNT2L0nyRJLZJF9OclZbP7vtz7bjk2s0uyRpEct55X4r8PzA/h3AnVX1UeANYHdb3w280dbvbOdJktbRkuKeZAtwHfDXbT/AVcCD7ZR9wPVte2fbpx3f0c6XJK2Tpb5y/wvgD4Aft/0LgDer6njbPwJsbtubgcMA7fhb7XxJ0joZGvcknwGOVdWTo3zgJNNJZpLMzM3NjfJbS9Jpbymv3D8J/GaSl4D7mb8c80VgY5IN7ZwtwNG2fRTYCtCOnwu8fvI3raq9VTVVVVMTExOr+iEkSe81NO5V9UdVtaWqJoEbgUeq6reAR4HPttN2Afvb9oG2Tzv+SFXVSKeWJL2v1bzP/Q+B25LMMn9N/Z62fg9wQVu/DdizuhElScu1Yfgp/6+qHgMea9svAlcscM73gc+NYDZJ0gr5CVVJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6tDQuCf5qST/keQ/kzyX5E/a+iVJnkgym+TLSc5q62e3/dl2fHKNfwZJ0kmW8sr9B8BVVfVx4FLg6iRXAncAd1bVR4E3gN3t/N3AG239znaeJGkdDY17zXun7Z7Zvgq4Cniwre8Drm/bO9s+7fiOJBnVwJKk4ZZ0zT3JGUmeBo4BB4HvAG9W1fF2yhFgc9veDBwGaMffAi4Y4cySpCGWFPeq+lFVXQpsAa4APrbaB04ynWQmyczc3Nxqv50kacCy3i1TVW8CjwKfADYm2dAObQGOtu2jwFaAdvxc4PUFvtfeqpqqqqmJiYmVTS9JWtBS3i0zkWRj2/4w8GngeeYj/9l22i5gf9s+0PZpxx+pqhrhzJKkITYMP4WLgH1JzmD+H4MHquqhJN8C7k/yp8BTwD3t/HuALyWZBb4H3LgGc0uS3sfQuFfVM8BlC6y/yPz195PXvw98biTTSZJWxE+oSlKHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdci4S1KHjLskdWjDuAeQlmtyz1fHPcKaeen268Y9gjrhK3dJ6pBxl6QODY17kq1JHk3yrSTPJbm1rZ+f5GCSF9rteW09Se5KMpvkmSSXr/UPIUl6r6W8cj8O/H5VbQeuBG5Jsh3YAxyqqm3AobYPcA2wrX1NA3ePfGpJ0vsaGveqeqWqvtG2/wd4HtgM7AT2tdP2Ade37Z3AfTXvcWBjkotGPbgkaXHLuuaeZBK4DHgC2FRVr7RDrwKb2vZm4PDA3Y60NUnSOlly3JOcA/wj8HtV9fbgsaoqoJbzwEmmk8wkmZmbm1vOXSVJQywp7knOZD7sf1dV/9SWXztxuaXdHmvrR4GtA3ff0tbeo6r2VtVUVU1NTEysdH5J0gKW8m6ZAPcAz1fVnw8cOgDsatu7gP0D6ze1d81cCbw1cPlGkrQOlvIJ1U8Cvw08m+TptvbHwO3AA0l2Ay8DN7RjDwPXArPAu8DNoxxYkjTc0LhX1b8BWeTwjgXOL+CWVc4lSVoFP6EqSR0y7pLUIX8rpKR10/Nv9IQP1m/19JW7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh4bGPcm9SY4l+ebA2vlJDiZ5od2e19aT5K4ks0meSXL5Wg4vSVrYUl65/y1w9Ulre4BDVbUNONT2Aa4BtrWvaeDu0YwpSVqOoXGvqn8FvnfS8k5gX9veB1w/sH5fzXsc2JjkohHNKklaopVec99UVa+07VeBTW17M3B44LwjbU2StI5W/R+qVVVALfd+SaaTzCSZmZubW+0YkqQBK437aycut7TbY239KLB14Lwtbe0nVNXeqpqqqqmJiYkVjiFJWshK434A2NW2dwH7B9Zvau+auRJ4a+DyjSRpnWwYdkKSfwA+BVyY5AjwBeB24IEku4GXgRva6Q8D1wKzwLvAzWswsyRpiKFxr6rPL3JoxwLnFnDLaoeSJK2On1CVpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nq0JrEPcnVSb6dZDbJnrV4DEnS4kYe9yRnAH8JXANsBz6fZPuoH0eStLi1eOV+BTBbVS9W1Q+B+4Gda/A4kqRFbFiD77kZODywfwT45ZNPSjINTLfdd5J8ew1m+aC4EPjuej1Y7livRzot+Nyd2np//j6y2IG1iPuSVNVeYO+4Hn89JZmpqqlxz6Hl87k7tZ3Oz99aXJY5Cmwd2N/S1iRJ62Qt4v51YFuSS5KcBdwIHFiDx5EkLWLkl2Wq6niS3wG+BpwB3FtVz436cU4xp8Xlp0753J3aTtvnL1U17hkkSSPmJ1QlqUPGXZI6ZNwlqUPGfQ0kuSLJL7Xt7UluS3LtuOeSepfkY0l2JDnnpPWrxzXTuPgfqiOW5AvM/16dDcBB5j+d+yjwaeBrVfVnYxxPq5Dk5qr6m3HPoYUl+V3gFuB54FLg1qra3459o6ouH+N46864j1iSZ5n/g3U28CqwpareTvJh4Imq+oVxzqeVS/LfVXXxuOfQwtrfvU9U1TtJJoEHgS9V1ReTPFVVl413wvU1tl8/0LHjVfUj4N0k36mqtwGq6n+T/HjMs2mIJM8sdgjYtJ6zaNk+VFXvAFTVS0k+BTyY5CPMP3+nFeM+ej9M8tNV9S7wiycWk5wLGPcPvk3AbwBvnLQe4N/Xfxwtw2tJLq2qpwHaK/jPAPcCPz/WycbAuI/er1bVDwCqajDmZwK7xjOSluEh4JwTgRiU5LF1n0bLcRNwfHChqo4DNyX5q/GMND5ec5ekDvlWSEnqkHGXpA4Zd0nqkHGXpA4Zd0nq0P8BtUDm+oxycMQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.Pclass.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.Embarked.value_counts(dropna=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.Age.plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.Fare.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Препроцессинг данных\n",
    "Для каждого признака необходимо:\n",
    "* Заменить пропуски\n",
    "* Для категориальных текстовых признаков получить категориальные числовые (признак *Sex*). Попробовать из sklearn `LabelEncoder` и `OneHotEncoder` (на выбор)\n",
    "* Нормализовать признаки\n",
    "\n",
    "Замена пропусков может быть реализована через:\n",
    "* заменой средним\n",
    "* заменой медианой\n",
    "* заменой модой (наиболее встречающимся значением)\n",
    "* для категориальных признаков заменой наиболее встречающимся значением или созданием новой категории \"не определено\"\n",
    "* заменой следующим или предыдущим значением (`fillna`)\n",
    "\n",
    "Нормализация (*sklearn*):\n",
    "* `MinMaxScaler`\n",
    "* `StandartScaler`\n",
    "* `RobustScaler`\n",
    "\n",
    "Сделать для *train* и *test* данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.replace(to_replace={'male': 1, 'female': 0}, inplace=True)\n",
    "train['Embarked'].dropna()\n",
    "train.drop(['Name','Ticket','Cabin'], inplace=True, axis=1)\n",
    "train['Age'] = train.Age.fillna(train.Age.mean())\n",
    "train.replace(to_replace={'S': 0, 'C': 1,'Q':2}, inplace=True)\n",
    "train['Embarked'] = train.Embarked.fillna(3)\n",
    "train.Embarked = train.Embarked.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "st_scaler = StandardScaler()\n",
    "ro_scaler = RobustScaler()\n",
    "train_mm = pd.DataFrame(mm_scaler.fit_transform(train),columns=train.keys())\n",
    "train_st = pd.DataFrame(st_scaler.fit_transform(train),columns=train.keys())\n",
    "train_ro = pd.DataFrame(ro_scaler.fit_transform(train),columns=train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.replace(to_replace={'male': 1, 'female': 0}, inplace=True)\n",
    "test['Embarked'].dropna()\n",
    "test.drop(['Name','Ticket','Cabin'], inplace=True, axis=1)\n",
    "test['Age'] = test.Age.fillna(test.Age.mean())\n",
    "test.replace(to_replace={'S': 0, 'C': 1,'Q':2}, inplace=True)\n",
    "test['Embarked'] = test.Embarked.fillna(3)\n",
    "test.Embarked = test.Embarked.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[(test.Pclass==3), 'Fare'] = test.loc[(test.Pclass==3), 'Fare'].fillna(test.loc[(test.Pclass==3), 'Fare'].mean())\n",
    "test.loc[(test.Pclass==2), 'Fare'] = test.loc[(test.Pclass==2), 'Fare'].fillna(test.loc[(test.Pclass==2), 'Fare'].mean())\n",
    "test.loc[(test.Pclass==1), 'Fare'] = test.loc[(test.Pclass==1), 'Fare'].fillna(test.loc[(test.Pclass==1), 'Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Fare.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_scaler = StandardScaler()\n",
    "test_st = pd.DataFrame(st_scaler.fit_transform(test),columns=test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Разбить данные для обучения на тренировочную и валидационную выборки. Для оценки качества модели необходимо проверить полученную модель на валидационных данных  (`train_test_split(X, y, random_state=42, stratify=y, test_size=20)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mm, X_test_mm, y_train_mm, y_test_mm = train_test_split(train_mm.drop('Survived',axis=1), train.Survived, random_state=42, test_size=20)\n",
    "X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(train_st.drop('Survived',axis=1), train.Survived, random_state=42, test_size=20)\n",
    "X_train_ro, X_test_ro, y_train_ro, y_test_ro = train_test_split(train_ro.drop('Survived',axis=1), train.Survived, random_state=42, test_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** \n",
    "#### Обучить на предобработанных данных следующие модели:\n",
    "* Логистическая регрессия (`LogisticRegression`)\n",
    "* Машины опорных векторов (`SVC`)\n",
    "* Метод ближайших соседей (`KNeighborsClassifier`)\n",
    "* Наивый байес (`GaussianNB`)\n",
    "* Дерево решений (`DecisionTreeClassifier`)\n",
    "* Случайный лес (`RandomForestClassifier`)\n",
    "* Градиентный бустинг (`GradientBoostingClassifier`)\n",
    "\n",
    "#### С каждой модели снять метрики, полученные на валидационных данных. Получить:\n",
    "* *Accuracy*\n",
    "* *Precision*\n",
    "* *Recall*\n",
    "* *F1-score*\n",
    "* *ConfusionMatrix*\n",
    "\n",
    "**Tip**:\n",
    "`sklearn.metrics.classification_report`\n",
    "\n",
    "#### Для каждой модели подобрать гиперпараметры, приносящие лучший скор на валидационных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_mm = LogisticRegression().fit(X_train_mm, y_train_mm)\n",
    "pred_mm = clf_mm.predict(X_test_mm)\n",
    "\n",
    "clf_st = LogisticRegression().fit(X_train_st, y_train_st)\n",
    "pred_st = clf_st.predict(X_test_st)\n",
    "\n",
    "clf_ro = LogisticRegression().fit(X_train_ro, y_train_ro)\n",
    "pred_ro = clf_ro.predict(X_test_ro)\n",
    "\n",
    "print(classification_report(y_test_mm,pred_mm))\n",
    "\n",
    "print(classification_report(y_test_st,pred_st))\n",
    "\n",
    "print(classification_report(y_test_ro,pred_ro))\n",
    "\n",
    "results['Logistic Regression'] = [accuracy_score(y_test_mm, pred_mm), accuracy_score(y_test_st, pred_st), accuracy_score(y_test_ro, pred_ro)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print(f'{accuracy_score(y_test_ro, pred_ro)=}')\\nprint(f'{precision_score(y_test_ro, pred_ro)=}')\\nprint(f'{recall_score(y_test_ro, pred_ro)=}')\\nprint(f'{f1_score(y_test_ro, pred_ro)=}')\\nprint(confusion_matrix(y_test_ro, pred_ro))\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(f'{accuracy_score(y_test_mm, pred_mm)=}')\n",
    "print(f'{precision_score(y_test_mm, pred_mm)=}')\n",
    "print(f'{recall_score(y_test_mm, pred_mm)=}')\n",
    "print(f'{f1_score(y_test_mm, pred_mm)=}')\n",
    "print(confusion_matrix(y_test_mm, pred_mm))\"\"\"\n",
    "\n",
    "\"\"\"print(f'{accuracy_score(y_test_st, pred_st)=}')\n",
    "print(f'{precision_score(y_test_st, pred_st)=}')\n",
    "print(f'{recall_score(y_test_st, pred_st)=}')\n",
    "print(f'{f1_score(y_test_st, pred_st)=}')\n",
    "print(confusion_matrix(y_test_st, pred_st))\"\"\"\n",
    "\n",
    "\"\"\"print(f'{accuracy_score(y_test_ro, pred_ro)=}')\n",
    "print(f'{precision_score(y_test_ro, pred_ro)=}')\n",
    "print(f'{recall_score(y_test_ro, pred_ro)=}')\n",
    "print(f'{f1_score(y_test_ro, pred_ro)=}')\n",
    "print(confusion_matrix(y_test_ro, pred_ro))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        10\n",
      "           1       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.85      0.85      0.85        20\n",
      "weighted avg       0.85      0.85      0.85        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_mm = make_pipeline(MinMaxScaler(), SVC(gamma='auto'))\n",
    "svc_st = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "svc_ro = make_pipeline(RobustScaler(), SVC(gamma='auto'))\n",
    "\n",
    "clf_svc_mm = svc_mm.fit(X_train_mm, y_train_mm)\n",
    "clf_svc_st = svc_st.fit(X_train_st, y_train_st)\n",
    "clf_svc_ro = svc_ro.fit(X_train_ro, y_train_ro)\n",
    "\n",
    "pred_svc_mm = clf_svc_mm.predict(X_test_mm)\n",
    "pred_svc_st = clf_svc_st.predict(X_test_st)\n",
    "pred_svc_ro = clf_svc_ro.predict(X_test_ro)\n",
    "\n",
    "\n",
    "print(classification_report(y_test_mm,pred_svc_mm))\n",
    "\n",
    "print(classification_report(y_test_st,pred_svc_st))\n",
    "\n",
    "print(classification_report(y_test_ro,pred_svc_ro))\n",
    "\n",
    "results['SVC'] = [accuracy_score(y_test_mm, pred_svc_mm), accuracy_score(y_test_st, pred_svc_st), accuracy_score(y_test_ro, pred_svc_ro)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##  1  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  2  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  3  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  4  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  5  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  6  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  7  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  8  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  9  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  10  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  11  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  12  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  13  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  14  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  15  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  16  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  17  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82        10\n",
      "           1       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.81      0.80      0.80        20\n",
      "weighted avg       0.81      0.80      0.80        20\n",
      "\n",
      "##  18  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  19  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  20  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  21  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  22  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  23  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  24  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  25  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  26  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  27  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  28  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  29  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  30  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  31  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  32  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  33  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  34  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  35  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  36  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  37  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  38  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  39  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  40  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  41  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  42  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  43  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  44  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  45  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  46  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  47  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  48  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  49  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "##  50  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  51  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  52  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  53  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##  54  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  55  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  56  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  57  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  58  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  59  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  60  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  61  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.88      0.85      0.85        20\n",
      "weighted avg       0.88      0.85      0.85        20\n",
      "\n",
      "##  62  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  63  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        10\n",
      "           1       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.86      0.80      0.79        20\n",
      "weighted avg       0.86      0.80      0.79        20\n",
      "\n",
      "##  64  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  65  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  66  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  67  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  68  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  69  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  70  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  71  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  72  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  73  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  74  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  75  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  76  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  77  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  78  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  79  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  80  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  81  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  82  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  83  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  84  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  85  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  86  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  87  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  88  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  89  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75        10\n",
      "           1       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.74      0.70      0.69        20\n",
      "weighted avg       0.74      0.70      0.69        20\n",
      "\n",
      "##  90  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  91  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75        10\n",
      "           1       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.74      0.70      0.69        20\n",
      "weighted avg       0.74      0.70      0.69        20\n",
      "\n",
      "##  92  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75        10\n",
      "           1       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.74      0.70      0.69        20\n",
      "weighted avg       0.74      0.70      0.69        20\n",
      "\n",
      "##  93  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75        10\n",
      "           1       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.74      0.70      0.69        20\n",
      "weighted avg       0.74      0.70      0.69        20\n",
      "\n",
      "##  94  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75        10\n",
      "           1       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.74      0.70      0.69        20\n",
      "weighted avg       0.74      0.70      0.69        20\n",
      "\n",
      "##  95  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75        10\n",
      "           1       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.74      0.70      0.69        20\n",
      "weighted avg       0.74      0.70      0.69        20\n",
      "\n",
      "##  96  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  97  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  98  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n",
      "##  99  ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh_mms = list(KNeighborsClassifier(n_neighbors=i) for i in range(1,100))\n",
    "\n",
    "for i in range(99):\n",
    "    neigh_mms[i].fit(X_train_ro, y_train_ro)\n",
    "\n",
    "pred_Kneigh_mms = list(neigh_mms[i].predict(X_test_ro) for i in range(99))\n",
    "\n",
    "for i in range(99):\n",
    "    print('## ',i+1,' ##')\n",
    "    print(classification_report(y_test_ro, pred_Kneigh_mms[i]))\n",
    "# лучшее для MinMaxScaler при n_neighbors=21, для StandardScaler = 23, для RobustScaler = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh_mm = KNeighborsClassifier(n_neighbors=21)\n",
    "neigh_st = KNeighborsClassifier(n_neighbors=23)\n",
    "neigh_ro = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "neigh_mm.fit(X_train_mm, y_train_mm)\n",
    "neigh_st.fit(X_train_st, y_train_st)\n",
    "neigh_ro.fit(X_train_ro, y_train_ro)\n",
    "\n",
    "pred_Kneigh_mm = neigh_mm.predict(X_test_mm)\n",
    "pred_Kneigh_st = neigh_st.predict(X_test_st)\n",
    "pred_Kneigh_ro = neigh_ro.predict(X_test_ro)\n",
    "\n",
    "print(classification_report(y_test_mm, pred_Kneigh_mm))\n",
    "print(classification_report(y_test_st, pred_Kneigh_st))\n",
    "print(classification_report(y_test_ro, pred_Kneigh_ro))\n",
    "\n",
    "results['KNeighborsClassifier'] = [accuracy_score(y_test_mm, pred_Kneigh_mm), accuracy_score(y_test_st, pred_Kneigh_st), accuracy_score(y_test_ro, pred_Kneigh_ro)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_gauss_mm = GaussianNB()\n",
    "clf_gauss_st = GaussianNB()\n",
    "clf_gauss_ro = GaussianNB()\n",
    "\n",
    "clf_gauss_mm.fit(X_train_mm, y_train_mm)\n",
    "clf_gauss_st.fit(X_train_st, y_train_st)\n",
    "clf_gauss_ro.fit(X_train_ro, y_train_ro)\n",
    "\n",
    "pred_gauss_mm = clf_gauss_mm.predict(X_test_mm)\n",
    "pred_gauss_st = clf_gauss_st.predict(X_test_st)\n",
    "pred_gauss_ro = clf_gauss_ro.predict(X_test_ro)\n",
    "\n",
    "print(classification_report(y_test_mm,pred_gauss_mm))\n",
    "print(classification_report(y_test_st,pred_gauss_st))\n",
    "print(classification_report(y_test_ro,pred_gauss_ro))\n",
    "\n",
    "results['GaussianNB'] = [accuracy_score(y_test_mm, pred_gauss_mm), accuracy_score(y_test_st, pred_gauss_st), accuracy_score(y_test_ro, pred_gauss_ro)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82        10\n",
      "           1       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.81      0.80      0.80        20\n",
      "weighted avg       0.81      0.80      0.80        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82        10\n",
      "           1       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.81      0.80      0.80        20\n",
      "weighted avg       0.81      0.80      0.80        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82        10\n",
      "           1       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.81      0.80      0.80        20\n",
      "weighted avg       0.81      0.80      0.80        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tree_mm = DecisionTreeClassifier(random_state=0)\n",
    "clf_tree_st = DecisionTreeClassifier(random_state=0)\n",
    "clf_tree_ro = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf_tree_mm.fit(X_train_mm, y_train_mm)\n",
    "clf_tree_st.fit(X_train_st, y_train_st)\n",
    "clf_tree_ro.fit(X_train_ro, y_train_ro)\n",
    "\n",
    "pred_tree_mm = clf_tree_mm.predict(X_test_mm)\n",
    "pred_tree_st = clf_tree_st.predict(X_test_st)\n",
    "pred_tree_ro = clf_tree_ro.predict(X_test_ro)\n",
    "\n",
    "print(classification_report(y_test_mm, pred_tree_mm))\n",
    "print(classification_report(y_test_st, pred_tree_st))\n",
    "print(classification_report(y_test_ro, pred_tree_ro))\n",
    "\n",
    "results['Decision'] = [accuracy_score(y_test_mm, pred_tree_mm), accuracy_score(y_test_st, pred_tree_st), accuracy_score(y_test_ro, pred_tree_ro)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_forest_mm = RandomForestClassifier()\n",
    "clf_forest_st = RandomForestClassifier()\n",
    "clf_forest_ro = RandomForestClassifier()\n",
    "\n",
    "clf_forest_mm.fit(X_train_mm, y_train_mm)\n",
    "clf_forest_st.fit(X_train_st, y_train_st)\n",
    "clf_forest_ro.fit(X_train_ro, y_train_ro)\n",
    "\n",
    "pred_forest_mm = clf_forest_mm.predict(X_test_mm)\n",
    "pred_forest_st = clf_forest_st.predict(X_test_st)\n",
    "pred_forest_ro = clf_forest_ro.predict(X_test_ro)\n",
    "\n",
    "print(classification_report(y_test_mm, pred_forest_mm))\n",
    "print(classification_report(y_test_st, pred_forest_st))\n",
    "print(classification_report(y_test_ro, pred_forest_ro))\n",
    "\n",
    "results['RandomForestClassifier'] = [accuracy_score(y_test_mm, pred_forest_mm), accuracy_score(y_test_st, pred_forest_st), accuracy_score(y_test_ro, pred_forest_ro)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_grad_mm = GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=1, random_state=0)\n",
    "clf_grad_st = GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=1, random_state=0)\n",
    "clf_grad_ro = GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=1, random_state=0)\n",
    "\n",
    "clf_grad_mm.fit(X_train_mm, y_train_mm)\n",
    "clf_grad_st.fit(X_train_st, y_train_st)\n",
    "clf_grad_ro.fit(X_train_ro, y_train_ro)\n",
    "\n",
    "pred_grad_mm = clf_grad_mm.predict(X_test_mm)\n",
    "pred_grad_st = clf_grad_st.predict(X_test_st)\n",
    "pred_grad_ro = clf_grad_ro.predict(X_test_ro)\n",
    "\n",
    "print(classification_report(y_test_mm, pred_grad_mm))\n",
    "print(classification_report(y_test_st, pred_grad_st))\n",
    "print(classification_report(y_test_ro, pred_grad_ro))\n",
    "\n",
    "results['GradientBoostingClassifier'] = [accuracy_score(y_test_mm, pred_grad_mm), accuracy_score(y_test_st, pred_grad_st), accuracy_score(y_test_ro, pred_grad_ro)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробовал RocAucCurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr,_ = roc_curve(y_test_mm, pred_grad_mm)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВЫВОД #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <th>StandardScaler</th>\n",
       "      <th>RobustScaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MinMaxScaler  StandardScaler  RobustScaler\n",
       "Logistic Regression                 0.90            0.90          0.90\n",
       "SVC                                 0.85            0.90          0.90\n",
       "KNeighborsClassifier                0.95            0.95          0.90\n",
       "GaussianNB                          0.90            0.90          0.90\n",
       "Decision                            0.80            0.80          0.80\n",
       "RandomForestClassifier              0.90            0.95          0.90\n",
       "GradientBoostingClassifier          0.95            0.95          0.95"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results,index=['MinMaxScaler','StandardScaler','RobustScaler']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно наибольная точность достигается при KNeighborsClassifier и GradientBoostingClassifier.Попробую $\\color{red}{\\text{TODO}}$ Буду использовать StandardScaler.\n",
    "Впринципе особой разницы нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_neigh = neigh_st.predict(test_st)\n",
    "pred_test_grad = clf_grad_st.predict(test_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** \n",
    "#### Получить лучший результ на kaggle.com\n",
    "* Зарегистрироваться на https://www.kaggle.com\n",
    "* Перейти по ссылке: https://www.kaggle.com/c/titanic/submit\n",
    "* Засабмитить полученный csv файл и получить результат (*accuracy*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_Xnew = clf_tree_st.predict(test_st).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': ypred_Xnew })\n",
    "submission.to_csv(\"submission_tree.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.770"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дальнейшие попытки #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.replace(to_replace={'male': 1, 'female': 0}, inplace=True)\n",
    "train.loc[(train.Pclass==3), 'Fare'] = train.loc[(train.Pclass==3), 'Fare'].fillna(train.loc[(train.Pclass==3), 'Fare'].mean())\n",
    "train.loc[(train.Pclass==2), 'Fare'] = train.loc[(train.Pclass==2), 'Fare'].fillna(train.loc[(train.Pclass==2), 'Fare'].mean())\n",
    "train.loc[(train.Pclass==1), 'Fare'] = train.loc[(train.Pclass==1), 'Fare'].fillna(train.loc[(train.Pclass==1), 'Fare'].mean())\n",
    "train['Age'] = train.Age.fillna(train.Age.median())\n",
    "train.replace(to_replace={'S': 0, 'C': 1,'Q':2}, inplace=True)\n",
    "train['Embarked'] = train.Embarked.fillna(3)\n",
    "train.Embarked = train.Embarked.astype(int)\n",
    "train.drop(['Name','Ticket'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "train['Spaces'] = train.Cabin.str.count(' ')\n",
    "train['Spaces'] = train.Spaces.fillna(-1)\n",
    "train.Cabin = train.Cabin.str.slice(stop=1)\n",
    "train['Cabin'] = train.Cabin.fillna('H')\n",
    "letters = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"T\"]\n",
    "train.Cabin.replace(to_replace=dict(zip(letters,list(range(len(letters))))), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    687\n",
       " 0.0    180\n",
       " 1.0     16\n",
       " 2.0      6\n",
       " 3.0      2\n",
       "Name: Spaces, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Spaces.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_scaler = StandardScaler()\n",
    "train_st = pd.DataFrame(st_scaler.fit_transform(train),columns=train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(train_st.drop('Survived',axis=1), train.Survived, random_state=42, test_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.92      0.90      0.90        20\n",
      "weighted avg       0.92      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_st = LogisticRegression(max_iter=10000).fit(X_train_st, y_train_st)\n",
    "pred_st = clf_st.predict(X_test_st)\n",
    "print(classification_report(y_test_st,pred_st))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.replace(to_replace={'male': 1, 'female': 0}, inplace=True)\n",
    "test.loc[(test.Pclass==3), 'Fare'] = test.loc[(test.Pclass==3), 'Fare'].fillna(test.loc[(test.Pclass==3), 'Fare'].mean())\n",
    "test.loc[(test.Pclass==2), 'Fare'] = test.loc[(test.Pclass==2), 'Fare'].fillna(test.loc[(test.Pclass==2), 'Fare'].mean())\n",
    "test.loc[(test.Pclass==1), 'Fare'] = test.loc[(test.Pclass==1), 'Fare'].fillna(test.loc[(test.Pclass==1), 'Fare'].mean())\n",
    "test['Age'] = test.Age.fillna(test.Age.median())\n",
    "test.replace(to_replace={'S': 0, 'C': 1,'Q':2}, inplace=True)\n",
    "test['Embarked'] = test.Embarked.fillna(3)\n",
    "test.Embarked = test.Embarked.astype(int)\n",
    "test.drop(['Name','Ticket'], inplace=True, axis=1)\n",
    "test['Spaces'] = test.Cabin.str.count(' ')\n",
    "test['Spaces'] = test.Spaces.fillna(-1)\n",
    "test.Cabin = test.Cabin.str.slice(stop=1)\n",
    "test['Cabin'] = test.Cabin.fillna('H')\n",
    "letters = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"T\"]\n",
    "test.Cabin.replace(to_replace=dict(zip(letters,list(range(len(letters))))), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Pclass         0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "Spaces         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_scaler = StandardScaler()\n",
    "test_st = pd.DataFrame(st_scaler.fit_transform(test),columns=test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_Xnew = clf_st.predict(test_st).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': ypred_Xnew })\n",
    "submission.to_csv(\"submission10000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.763"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neigh_st = KNeighborsClassifier(n_neighbors=31)\n",
    "\n",
    "neigh_st.fit(X_train_st, y_train_st)\n",
    "pred_Kneigh_st = neigh_st.predict(X_test_st)\n",
    "print(classification_report(y_test_st, pred_Kneigh_st))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_Xnew = neigh_st.predict(test_st).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': ypred_Xnew })\n",
    "submission.to_csv(\"submission_new_neigh31.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_grad_st = GradientBoostingClassifier(n_estimators=50, learning_rate=0.5, max_depth=1, random_state=0)\n",
    "clf_grad_st.fit(X_train_st, y_train_st)\n",
    "pred_grad_st = clf_grad_st.predict(X_test_st)\n",
    "print(classification_report(y_test_st, pred_grad_st))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_Xnew = clf_grad_st.predict(test_st).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': ypred_Xnew })\n",
    "submission.to_csv(\"submission_new_grad.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['PassengerId','Name', 'SibSp', 'Parch','Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "train.Embarked = train['Embarked'].replace(to_replace={np.nan: train.Embarked.mode().to_list()[0]})\n",
    "\n",
    "embarked_unique = train.Embarked.unique()\n",
    "for i in embarked_unique:\n",
    "    train[i] = train.Embarked==i\n",
    "\n",
    "train = train.drop('Embarked',axis=1)\n",
    "\n",
    "train.Age = train.Age.fillna(train.Age.mean())\n",
    "\n",
    "le = LabelEncoder()\n",
    "for i in embarked_unique:\n",
    "    le.fit(train[i])\n",
    "    train[i] = le.transform(train[i])\n",
    "le.fit(train.Sex)\n",
    "train.Sex = le.transform(train.Sex)\n",
    "\n",
    "for i in train.Pclass.unique():\n",
    "    train.loc[(train.Pclass==i), 'Fare'] = train.loc[(train.Pclass==i), 'Fare'].fillna(train.loc[(train.Pclass==i), 'Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_st = pd.DataFrame(scaler.fit_transform(train),columns=train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(train_st.drop('Survived',axis=1), train.Survived, random_state=42, test_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "clf.fit(X_train_st,y_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=22)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=22)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=22)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=22)\n",
    "\n",
    "clf.fit(X_train_st,y_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train_st,y_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_id = test.PassengerId\n",
    "test = test.drop(columns=['PassengerId','Name', 'SibSp', 'Parch','Ticket', 'Cabin'], axis=1)\n",
    "test.Embarked = test['Embarked'].replace(to_replace={np.nan: test.Embarked.mode().to_list()[0]})\n",
    "\n",
    "embarked_unique = test.Embarked.unique()\n",
    "for i in embarked_unique:\n",
    "    test[i] = test.Embarked==i\n",
    "test = test.drop('Embarked',axis=1)\n",
    "\n",
    "test.Age = test.Age.fillna(test.Age.mean())\n",
    "le = LabelEncoder()\n",
    "for i in embarked_unique:\n",
    "    le.fit(test[i])\n",
    "    test[i] = le.transform(test[i])\n",
    "le.fit(test.Sex)\n",
    "test.Sex = le.transform(test.Sex)\n",
    "for i in test.Pclass.unique():\n",
    "    test.loc[(test.Pclass==i), 'Fare'] = test.loc[(test.Pclass==i), 'Fare'].fillna(test.loc[(test.Pclass==i), 'Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_st = pd.DataFrame(scaler.fit_transform(test),columns=test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\roman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ypred_Xnew = clf.predict(test_st).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId': pas_id, 'Survived': ypred_Xnew })\n",
    "submission.to_csv(\"submission_final2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>S</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex        Age     Fare  S  C  Q\n",
       "0           0       3    1  22.000000   7.2500  1  0  0\n",
       "1           1       1    0  38.000000  71.2833  0  1  0\n",
       "2           1       3    0  26.000000   7.9250  1  0  0\n",
       "3           1       1    0  35.000000  53.1000  1  0  0\n",
       "4           0       3    1  35.000000   8.0500  1  0  0\n",
       "..        ...     ...  ...        ...      ... .. .. ..\n",
       "886         0       2    1  27.000000  13.0000  1  0  0\n",
       "887         1       1    0  19.000000  30.0000  1  0  0\n",
       "888         0       3    0  29.699118  23.4500  1  0  0\n",
       "889         1       1    1  26.000000  30.0000  0  1  0\n",
       "890         0       3    1  32.000000   7.7500  0  0  1\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
